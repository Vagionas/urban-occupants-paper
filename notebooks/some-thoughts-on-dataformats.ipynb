{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some thoughts on data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consisting of the following 'tables':\n",
    "\n",
    "* one for each heterogeneous markov chain (size currently around 9k but rises exponentially with number of activities), of which there will be one for each person type\n",
    "* one for all dwellings with ~100k entries, including all thermal traits, a geolocation, and an ID to UKBuildings\n",
    "* one for all people with ~250k entries, mainly a link to a dwelling and a link to a markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working assumptions:\n",
    "\n",
    "* all simulation results fit in memory, which increases the number of possible solutions and is a simplifcation\n",
    "* results aren't compressed in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable = namedtuple('Variable', ['name', 'dtype', 'domain'])\n",
    "\n",
    "\n",
    "class Domain(Enum):\n",
    "    DWELLING = (101955)\n",
    "    RESIDENT = (254926)\n",
    "    \n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "        \n",
    "\n",
    "def analyse_size_of_result_in_giga_bytes(variables, number_time_steps):\n",
    "    print(\"{} steps\".format(number_time_steps))\n",
    "    print(\"{}\".format(\", \".join([\"{} ({})\".format(var.name, var.dtype) for var in variables])))\n",
    "    print(\"\")\n",
    "    bytesize_dwellings = sum([var.dtype.itemsize * var.domain.number * number_time_steps \n",
    "                             for var in variables if var.domain == Domain.DWELLING])\n",
    "    bytesize_residents = sum([var.dtype.itemsize * var.domain.number * number_time_steps \n",
    "                             for var in variables if var.domain == Domain.RESIDENT])\n",
    "    print(\"{:.2f} GB necessary for residents\".format(bytes_to_giga_bytes(bytesize_residents)))\n",
    "    print(\"{:.2f} GB necessary for dwellings\".format(bytes_to_giga_bytes(bytesize_dwellings)))\n",
    "    print(\"{:.2f} GB necessary in total\".format(bytes_to_giga_bytes(bytesize_dwellings + bytesize_residents)))\n",
    "    \n",
    "\n",
    "\n",
    "def bytes_to_giga_bytes(bytesize):\n",
    "    return bytesize / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    Variable('temperature', np.dtype(np.float32), Domain.DWELLING),\n",
    "    Variable('thermal_power', np.dtype(np.float32), Domain.DWELLING),\n",
    "    Variable('activity', np.dtype(np.int8), Domain.RESIDENT),\n",
    "]\n",
    "\n",
    "analyse_size_of_result_in_giga_bytes(variables, 8760 * 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing all data is too much. Not only will it be difficult to keep all results in memory, but also it is most probably more than we need.\n",
    "\n",
    "Reducing the temporal resolution to 1h might be a solution, even though it might be difficult to downscale people activity. In any case that would lead to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    Variable('temperature', np.dtype(np.float32), Domain.DWELLING),\n",
    "    Variable('thermal_power', np.dtype(np.float32), Domain.DWELLING),\n",
    "    Variable('activity', np.dtype(np.int8), Domain.RESIDENT),\n",
    "]\n",
    "\n",
    "analyse_size_of_result_in_giga_bytes(variables, 8760)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is doable, but still a lot. Would it be possible to use 16bit floats for some of the variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.finfo(np.dtype(np.float32)))\n",
    "print(np.finfo(np.dtype(np.float16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolution of the 16bit floating point should be enough for temperature and thermal power. Storing thermal power in kW will ensure values will fit into 16bit range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    Variable('temperature', np.dtype(np.float16), Domain.DWELLING),\n",
    "    Variable('thermal_power', np.dtype(np.float16), Domain.DWELLING),\n",
    "    Variable('activity', np.dtype(np.int8), Domain.RESIDENT),\n",
    "]\n",
    "\n",
    "analyse_size_of_result_in_giga_bytes(variables, 8760)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better, but must ensure its precise enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dev]",
   "language": "python",
   "name": "conda-env-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
