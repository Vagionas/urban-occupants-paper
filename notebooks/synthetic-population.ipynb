{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LONDON_BOUNDARY_FILE_URL = 'https://files.datapress.com/london/dataset/statistical-gis-boundary-files-london/2016-10-03T13:52:28/statistical-gis-boundaries-london.zip'\n",
    "LONDON_CENSUS_LABOUR_URL = 'https://files.datapress.com/london/dataset/2011-census-labour-and-qualifications/visualisation-data-labour.zip'\n",
    "LONDON_CENSUS_QUALIFICATION_URL = 'https://files.datapress.com/london/dataset/2011-census-labour-and-qualifications/visualisation-data-qualifications.zip'\n",
    "LONDON_CENSUS_WARD_POPULATION_URL = 'https://files.datapress.com/london/dataset/2011-census-demography/ward-pop-ONS-GLA-Census.xls'\n",
    "LONDON_CENSUS_BOROUGH_POPULATION_URL = 'https://files.datapress.com/london/dataset/2011-census-demography/london-unrounded-data.xls'\n",
    "LONDON_CENSUS_HOUSEHOLD_URL = 'https://files.datapress.com/london/dataset/2011-census-households-families/visualisation-data-households.zip'\n",
    "LONDON_CENSUS_HOUSING_URL = 'https://files.datapress.com/london/dataset/2011-census-housing/visualisation-data-housing.zip'\n",
    "\n",
    "LABOUR_FILE_PATH = Path('./LABOUR.xlsx')\n",
    "QUALIFICATION_FILE_PATH = Path('./QUALIFICATIONS.xlsx')\n",
    "HOUSEHOLDS_FILE_PATH = Path('./HOUSEHOLDS.xlsx')\n",
    "HOUSING_FILE_PATH = Path('./HOUSING.xlsx')\n",
    "BUILD_FOLDER = Path('./build')\n",
    "BUILD_FOLDER.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUMBER_USUAL_RESIDENTS = 254926 # http://www.haringey.gov.uk/sites/haringeygovuk/files/2011_census_haringey_briefing_on_key_statistics.pdf\n",
    "NUMBER_HOUSEHOLDS = 101955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import tempfile\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "requests_cache.install_cache((BUILD_FOLDER / 'cache').as_posix())\n",
    "\n",
    "def read_census_file(url, filename):\n",
    "    \"\"\"Reads census 2011 data from the London data store.\n",
    "    \n",
    "    The dataset is reduced to Haringey and ward resolution. All other data is discarded.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    with tempfile.TemporaryDirectory(prefix='london-census-files') as tmpdir:\n",
    "        z.extractall(path=tmpdir)\n",
    "        path_to_temp_file = Path(tmpdir) / filename\n",
    "        df = pd.read_excel(\n",
    "            path_to_temp_file, \n",
    "            sheetname='2011 Data',\n",
    "            skiprows=[0],\n",
    "            header=[0]\n",
    "        )\n",
    "    df.rename(columns={'Unnamed: 1': 'area_type'}, inplace=True)\n",
    "    df['area_type'] = df['area_type'].ffill()\n",
    "    df = df[(df.DISTLABEL == 'Haringey') & (df.area_type == 'ward')]\n",
    "    del df['DISTLABEL']\n",
    "    del df['area_type']\n",
    "    del df['ZONEID']\n",
    "    del df['Unnamed: 2']\n",
    "    df.set_index('ZONELABEL', inplace=True)\n",
    "    df.index.rename('ward', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce_census_data_to_tottenham(census_data):\n",
    "    return census_data[census_data.index.map(lambda label: 'Tottenham' in label)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def create_individual(df):\n",
    "    random_number = random.uniform(0, 1)\n",
    "    summed_probability = 0\n",
    "    for i in df.index:\n",
    "        if random_number < df.ix[i, 'total'] + summed_probability:\n",
    "            return df.ix[i, df.columns[:-1]].values\n",
    "        else:\n",
    "            summed_probability += df.ix[i, 'total']\n",
    "    raise ValueError('doh!')\n",
    "    \n",
    "\n",
    "def create_synthetic_population(df, column_names, pop_size, seed='syntheticpopulation'):\n",
    "    norm_df = df.copy()\n",
    "    norm_df.total = df.total / df.total.sum()\n",
    "    return pd.DataFrame(\n",
    "        data=(create_individual(norm_df) for i in range(pop_size)), \n",
    "        columns=column_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example not considering households\n",
    "\n",
    "Two attributes with two categories each:\n",
    "\n",
    "* age: 0-50yrs, 50-100yrs\n",
    "* sex: m, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class OrderedEnum(Enum):\n",
    "    def __ge__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value >= other.value\n",
    "        return NotImplemented\n",
    "    def __gt__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value > other.value\n",
    "        return NotImplemented\n",
    "    def __le__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value <= other.value\n",
    "        return NotImplemented\n",
    "    def __lt__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value < other.value\n",
    "        return NotImplemented\n",
    "\n",
    "class Age(OrderedEnum):\n",
    "    AGE0_50 = 1\n",
    "    AGE50_100 = 2\n",
    "    \n",
    "class Sex(OrderedEnum):\n",
    "    MALE = 1\n",
    "    FEMALE = 2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some microdata, the seed for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = (Age.AGE0_50, Sex.MALE)\n",
    "p2 = (Age.AGE0_50, Sex.MALE)\n",
    "p3 = (Age.AGE50_100, Sex.MALE)\n",
    "p4 = (Age.AGE0_50, Sex.FEMALE)\n",
    "p5 = (Age.AGE50_100, Sex.FEMALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make up some statistics about the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averages = {\n",
    "    Age.AGE0_50: 75,\n",
    "    Age.AGE50_100: 25,\n",
    "    Sex.MALE: 65,\n",
    "    Sex.FEMALE: 35\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Proportional Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_in = pd.DataFrame(\n",
    "        {\n",
    "            'sex': [Sex.MALE, Sex.MALE, Sex.FEMALE, Sex.FEMALE],\n",
    "            'age': [Age.AGE0_50, Age.AGE50_100, Age.AGE0_50, Age.AGE50_100],\n",
    "            'total': [2, 1, 1, 1]\n",
    "        }\n",
    "    )\n",
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xip = df_in.groupby('sex')['total'].sum()\n",
    "xpj = df_in.groupby('age')['total'].sum()\n",
    "\n",
    "xip.ix[Sex.MALE] = averages[Sex.MALE]\n",
    "xip.ix[Sex.FEMALE] = averages[Sex.FEMALE]\n",
    "\n",
    "xpj.ix[Age.AGE0_50] = averages[Age.AGE0_50]\n",
    "xpj.ix[Age.AGE50_100] = averages[Age.AGE50_100]\n",
    "\n",
    "aggregates = [xip, xpj]\n",
    "dimensions = [['sex'], ['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipfn import *\n",
    "\n",
    "IPF = ipfn.ipfn(\n",
    "    df_in,\n",
    "    aggregates, \n",
    "    dimensions\n",
    ")\n",
    "df_out = IPF.iteration()\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out.groupby('sex').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out.groupby('age').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers correctly mimic the population statistics.\n",
    "\n",
    "Next, based on these numbers let's create a synthetic population. Assuming the result can be understood as a joint probability mass function, we can run 100 monte carlo draws to draw 100 individuals from this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_individual(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthetic_population = create_synthetic_population(\n",
    "    df=df_out,\n",
    "    column_names=['age', 'sex'],\n",
    "    pop_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthetic_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synthetic_population.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the synthetic population!\n",
    "\n",
    "These numbers diverge slightly from the given population statistics but that's due to the nondeterministic drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: consider zones\n",
    "# TODO: consider households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Usual Resident Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_ward_population_data(url):\n",
    "    \"\"\"Reads census 2011 demographic data on ward level from the London data store.\n",
    "    \n",
    "    The dataset is reduced to Haringey and ward resolution. All other data is discarded.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    df = pd.read_excel(\n",
    "        io.BytesIO(r.content), \n",
    "        sheetname='2011 Census',\n",
    "        skiprows=[0],\n",
    "        header=[0]\n",
    "    )\n",
    "    df = df.ix[:, :23] # only totals, cut sex specifics\n",
    "    df = df[df.Borough == 'Haringey']\n",
    "    del df['Borough']\n",
    "    del df['Persons: All Ages'] # cut totals\n",
    "    del df['Ward Code']\n",
    "    df.set_index('Ward Name', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usual_residents = read_ward_population_data(LONDON_CENSUS_WARD_POPULATION_URL)\n",
    "usual_residents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert usual_residents.sum().sum() == NUMBER_USUAL_RESIDENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read total number of fifteen year old\n",
    "\n",
    "The number of fifteen year old is important as it is used to divide adults from youth in the census (see lateron). The ward population data set cuts based on 5 years and hence does not cut between youth and adults. For reference, the total number of fifteen year old is read in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_borough_population_data(url):\n",
    "    \"\"\"Reads census 2011 demographic data on borough level from the London data store.\"\"\"\n",
    "    r = requests.get(url)\n",
    "    df = pd.read_excel(\n",
    "        io.BytesIO(r.content), \n",
    "        sheetname='Persons',\n",
    "        skiprows=[0],\n",
    "        header=[0]\n",
    "    )\n",
    "    df.drop(df.columns[[0, 2]], axis=1, inplace=True)\n",
    "    df.drop([0, 34, 35, 36, 37, 38], axis=0, inplace=True)\n",
    "    df.rename(columns={'Unnamed: 1': 'ward'}, inplace=True)\n",
    "    df.set_index('ward', inplace=True)\n",
    "    df = df.astype(np.int16)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_fifteen_haringey = read_borough_population_data(LONDON_CENSUS_BOROUGH_POPULATION_URL).ix['Haringey', 15]\n",
    "total_fifteen_haringey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qualification_data = read_census_file(LONDON_CENSUS_QUALIFICATION_URL, QUALIFICATION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qualification_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert qualification_data.sum().sum() == usual_residents.ix[:, '15 to 19':].sum().sum() - total_fifteen_haringey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualification data is available for every usual resident starting from age 16. Unfortunately there is no data available on how many residents are older or younger than 16 (only 15) in the ward population data set. But obviously, we can infer the number of residents below 16 from the qualification data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "younger_than_sixteen = usual_residents.sum(axis=1) - qualification_data.sum(axis=1)\n",
    "younger_than_sixteen.name = 'usual residents below 16'\n",
    "younger_than_sixteen.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usual_residents_age_fifteen = younger_than_sixteen - usual_residents.ix[:, :'10 to 14'].sum(axis=1)\n",
    "usual_residents_age_fifteen.name = 'usual residents age 16'\n",
    "assert usual_residents_age_fifteen.sum() == total_fifteen_haringey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qualification_data['below_16'] = younger_than_sixteen\n",
    "assert qualification_data.sum().sum() == usual_residents.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labour_data = read_census_file(LONDON_CENSUS_LABOUR_URL, LABOUR_FILE_PATH)\n",
    "labour_data.drop(labour_data.columns[10:], axis=1, inplace=True)\n",
    "labour_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert labour_data.sum().sum() == usual_residents.ix[:, '15 to 19':'70 to 74'].sum().sum() - total_fifteen_haringey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labour data is available for every usual resident between age 16 and 74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labour_data['below_16'] = younger_than_sixteen\n",
    "labour_data['above_74'] = usual_residents.ix[:, '75 to 79':].sum(axis=1)\n",
    "assert labour_data.sum().sum() == usual_residents.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_data = read_census_file(LONDON_CENSUS_HOUSEHOLD_URL, HOUSEHOLDS_FILE_PATH)\n",
    "housing_data = read_census_file(LONDON_CENSUS_HOUSING_URL, HOUSING_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert (housing_data['Unshared dwelling: Total'] + housing_data['Shared dwelling']).sum() == NUMBER_HOUSEHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert NUMBER_USUAL_RESIDENTS - younger_than_sixteen.sum() == \\\n",
    "    (household_data['Single (never married or never registered a same-sex civil partnership)'] + \n",
    "     household_data['Married'] +\n",
    "     household_data['In a registered same-sex civil partnership'] +\n",
    "     household_data['Separated (but still legally married or still legally in a same-sex civil partnership)'] + \n",
    "     household_data['Divorced or formerly in a same-sex civil partnership which is now legally dissolved'] + \n",
    "     household_data['Widowed or surviving partner from a same-sex civil partnership']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_data.drop(household_data.columns[:29], axis=1, inplace=True)\n",
    "household_data.drop(household_data.columns[11:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "household_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Definition of a dependent child](http://www.ons.gov.uk/ons/guide-method/census/2011/census-data/2011-census-data/2011-first-release/2011-census-definitions/2011-census-glossary.pdf) in the 2011 census:\n",
    "\n",
    "> A dependent child is any person aged 0 to 15 in a household (whether or not in a family) or a person aged 16 to 18 in full-time education and living in a family with his or her parent(s) or grandparent(s). It does not include any people aged 16 to 18 who have a spouse, partner or child living in the household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert NUMBER_HOUSEHOLDS == household_data.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_data['Couple with dependent children'] = (household_data['Married couple household: With dependent children'] + \n",
    "                                                    household_data['Same-sex civil partnership couple household: With dependent children'] + \n",
    "                                                    household_data['Cohabiting couple household: With dependent children'])\n",
    "household_data['Lone parent with dependent children'] = household_data['Lone parent household: With dependent children']\n",
    "household_data.drop(['Married couple household: With dependent children',\n",
    "                     'Same-sex civil partnership couple household: With dependent children',\n",
    "                     'Cohabiting couple household: With dependent children',\n",
    "                     'Lone parent household: With dependent children'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_data['Couple without dependent children'] = (household_data['Married couple household: No dependent children'] + \n",
    "                                                       household_data['Same-sex civil partnership couple household: No dependent children'] + \n",
    "                                                       household_data['Cohabiting couple household: No dependent children'])\n",
    "household_data['One person household'] += household_data['Lone parent household: No dependent children']\n",
    "household_data.drop(['Married couple household: No dependent children',\n",
    "                     'Same-sex civil partnership couple household: No dependent children',\n",
    "                     'Cohabiting couple household: No dependent children',\n",
    "                     'Lone parent household: No dependent children'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_data['Multi-person household'] = (household_data['Multi-person household: Other'] +\n",
    "                                            household_data['Multi-person household: All full-time students'])\n",
    "household_data.drop(['Multi-person household: All full-time students',\n",
    "                     'Multi-person household: Other'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "household_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert NUMBER_HOUSEHOLDS == household_data.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Seed\n",
    "\n",
    "As for the moment there is no micro census data available, we'll use the Time Use Survey data as seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytus2000 import read_individual_file, individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = Path('./data/UKDA-4504-tab/')\n",
    "BUILD_FOLDER_PATH = Path('./build/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_cache = BUILD_FOLDER_PATH / 'pickled_individual_data'\n",
    "try:\n",
    "    individual_data = pd.read_pickle(individual_cache.as_posix())\n",
    "except:\n",
    "    individual_data = read_individual_file(DATA_FOLDER_PATH / 'tab' / 'individual_data_5.tab')\n",
    "    individual_data.to_pickle(individual_cache.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_data.groupby('ECONACT2').Q1A.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "econact2_to_census = {\n",
    "    individual.ECONACT2.ECON_ACTIVE___EMPLOYEE___FULL_TIME: 'Economically active: Employee: Full-time',\n",
    "    individual.ECONACT2.ECON_INACTIVE___LONG_TERM_SICK_DISABLED: 'Economically inactive: Long-term sick or disabled',\n",
    "    individual.ECONACT2.ECON_INACTIVE___OTHER_REASONS_EG_TEMP_SICK__BELIEVES_NO_JOBS: 'Economically inactive: Other',\n",
    "    individual.ECONACT2.ECON_INACTIVE___DK_REASONS: np.nan, #FIXME\n",
    "    individual.ECONACT2.ADULT___NOT_CLASSIFIABLE_EITHER_EMP__UNEMP_OR_INACTIVE: np.nan,\n",
    "    individual.ECONACT2.UNDER_16YRS___INELIGIBLE_FOR_EMPLOYMENT_QUESTIONS: 'below_16',\n",
    "    individual.ECONACT2.ECON_ACTIVE___EMPLOYEE___PART_TIME: 'Economically active: Employee: Part-time',\n",
    "    individual.ECONACT2.ECON_ACTIVE___SELF_EMPLOYED___FULL_TIME: 'Economically active: Self-employed',\n",
    "    individual.ECONACT2.ECON_ACTIVE___SELF_EMPLOYED___PART_TIME: 'Economically active: Self-employed',\n",
    "    individual.ECONACT2.ECON_ACTIVE___DK_EMPSELFFULLPART: np.nan, #FIXME\n",
    "    individual.ECONACT2.ECON_ACTIVE___UNEMPLOYED_ILO_DEFINITION: 'Economically active: Unemployed',\n",
    "    individual.ECONACT2.ECON_INACTIVE___RETIRED: 'Economically inactive: Retired',\n",
    "    individual.ECONACT2.ECON_INACTIVE___FULL_TIME_STUDENT: 'Economically inactive: Student (including full-time students)',\n",
    "    individual.ECONACT2.ECON_INACTIVE___LOOKING_AFTER_FAMILY_HOME: 'Economically inactive: Looking after home or family'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_data.groupby('HIQUAL4').Q1A.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hiqual4_to_census = { # FIXME all must be checked again\n",
    "    individual.HIQUAL4.DEGREE_LEVEL_QUALIFICATION_OR_ABOVE: 'Level 4/5',\n",
    "    individual.HIQUAL4.QUALIFICATIONS___CITY_AND_GUILDS___DK_LEVEL: np.nan,\n",
    "    individual.HIQUAL4.QUALIFICATIONS___OTHER___BUT_DK_GRADELEVEL: np.nan,\n",
    "    individual.HIQUAL4.NO_QUALIFICATIONS: 'No qualifications',\n",
    "    individual.HIQUAL4.ELIGIBLE___NO_ANSWER: np.nan,\n",
    "    individual.HIQUAL4.UNDER_16YRS___INELIGIBLE_FOR_QUALIFICATIONS_QUESTIONS: 'below_16',\n",
    "    individual.HIQUAL4.HIGHER_EDN_BELOW_DEGREE_LEVEL_EG_HNC__NURSING_QUAL: 'Level 3', # FIXME correct?\n",
    "    individual.HIQUAL4.A_LEVELS__VOCATIONAL_LEVEL_3_AND_EQUIVLNT_EG_AS_LEVEL__NVQ_3: 'Level 3',\n",
    "    individual.HIQUAL4.O_LEVELS__GCSE_GRADE_A_C__VOCATIONAL_LEVEL_2_AND_EQUIVLNT: 'Level 2',\n",
    "    individual.HIQUAL4.GCSE_BELOW_GRADE_C__CSE__VOCATIONAL_LEVEL_1_AND_EQUIVLNT: 'Level 1',\n",
    "    individual.HIQUAL4.QUALIFICATION_BELOW_GCSEO_LEVEL_EG_TRADE_APPRENTICESHIPS: 'Apprenticeship',\n",
    "    individual.HIQUAL4.OTHER_QUALIFICATION_INCL_PROFESSIONAL__VOCATIONAL__FOREIGN: 'Other qualificatinon',\n",
    "    individual.HIQUAL4.QUALIFICATIONS___BUT_DK_WHICH: 'Other qualificatinon',# FIXME correct?\n",
    "    individual.HIQUAL4.QUALIFICATIONS___GCSE___BUT_DK_GRADE: np.nan # FIXME correct?\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_data.groupby('HHTYPE4').IAGE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hhtype_to_census = {\n",
    "    individual.HHTYPE4.SINGLE_PERSON_HOUSEHOLD: 'One person household',\n",
    "    individual.HHTYPE4.SINGLE_PARENT___WITH_CHILDREN_GREATEREQUAL_16: 'Lone parent with dependent children',\n",
    "    individual.HHTYPE4.TWO_OR_MORE_COUPLES_MARRIED_OR_COHAB_WITHWITHOUT_CHILDRN: 'Multi-person household',\n",
    "    individual.HHTYPE4.SAME_SEX_COUPLES___SPONTANEOUSLY_DESCRIBED: 'Couple without dependent children',\n",
    "    individual.HHTYPE4.UNCLASSIFIED___MARRIED_COUPLES_IN_COMPLEX_HHLDS: 'Multi-person household',\n",
    "    individual.HHTYPE4.UNCLASSIFIED___COHABITING_COUPLES_IN_COMPLEX_HHLDS: 'Multi-person household',\n",
    "    individual.HHTYPE4.UNCLASSIFIED___SINGLE_PARENTS_IN_COMPLEX_HHLDS: 'Multi-person household',\n",
    "    individual.HHTYPE4.UNCLASSIFIED___OTHER_HHLDS_WITHOUT_COUPLES_EG_BROTHERS_DK: 'Multi-person household',\n",
    "    individual.HHTYPE4.HHLDS_WITH_2_OR_MORE_UNRELATED_PEOPLE_ONLY: 'Multi-person household',\n",
    "    individual.HHTYPE4.MARRIED_COUPLE___NO_CHILDREN_COUPLE_ONLY: 'Couple without dependent children',\n",
    "    individual.HHTYPE4.MARRIED_COUPLE___WITH_CHILDREN_SMALLEREQUAL_15: 'Couple with dependent children',\n",
    "    individual.HHTYPE4.MARRIED_COUPLE___WITH_CHILDREN_GREATEREQUAL_16: 'Couple with dependent children',\n",
    "    individual.HHTYPE4.COHAB_COUPLE___NO_CHILDREN_COUPLE_ONLY: 'Couple without dependent children',\n",
    "    individual.HHTYPE4.COHAB_COUPLE___WITH_CHILDREN_SMALLEREQUAL_15: 'Couple with dependent children',\n",
    "    individual.HHTYPE4.COHAB_COUPLE___WITH_CHILDREN_GREATEREQUAL_16: 'Couple with dependent children',\n",
    "    individual.HHTYPE4.SINGLE_PARENT____WITH_CHILDREN_SMALLEREQUAL_15: 'Lone parent with dependent children'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO filter city population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = pd.DataFrame(index=individual_data.index, columns=['labour', 'qualification', 'age', 'hhtype'])\n",
    "seed.labour = individual_data.ECONACT2.map(econact2_to_census)\n",
    "seed.labour[individual_data.IAGE > 74] = 'above_74'\n",
    "seed.qualification = individual_data.HIQUAL4.map(hiqual4_to_census)\n",
    "seed['age'] = individual_data.IAGE.copy()\n",
    "seed['hhtype'] = individual_data.HHTYPE4.map(hhtype_to_census)\n",
    "seed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economically active and full time students\n",
    "\n",
    "The statistics have the category of people that are full time students but still economically active. The TUS data does not have that category. The category we are looking for is the category of part time economically active and full time student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_data[(individual_data.ECONACT2 == individual.ECONACT2.ECON_INACTIVE___FULL_TIME_STUDENT) & \n",
    "                (individual_data.AGELEFT == individual.AGELEFT.NEVER_IN_FULL_TIME_EDUCATION)].IAGE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the categorization into labour status seems rather weak. For example, there is are 8 individuals that are categorized as a full time student that answered he/she has never been in full time education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part_time_working_students = individual_data[\n",
    "    (individual_data.ECONACT2 == individual.ECONACT2.ECON_ACTIVE___EMPLOYEE___PART_TIME) &\n",
    "    (individual_data.AGELEFT == individual.AGELEFT.STILL_IN_EDUCATION)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part_time_working_students.IAGE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, student in part_time_working_students.iterrows():\n",
    "    seed.ix[index, 'labour'] = 'Economically active: Full-time student'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Index for HIPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sn1_plus_sn2 = seed.index.droplevel(2)\n",
    "seed['household_id'] = list(sn1_plus_sn2)\n",
    "seed.reset_index(inplace=True)\n",
    "seed.rename(columns={'SN3': 'person_id'}, inplace=True)\n",
    "seed.set_index(['household_id', 'person_id'], inplace=True)\n",
    "seed.drop(['SN1', 'SN2'], axis=1, inplace=True)\n",
    "seed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN and invalid households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A household is invalid if the amount of individuals we have do not match the household type. For example, a couple without children household must have exactly two individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed.dropna(axis='index', how='any', inplace=True)\n",
    "assert not seed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_types = seed.groupby(seed.index.get_level_values(0)).hhtype.first()\n",
    "household_sizes = seed.groupby(seed.index.get_level_values(0)).hhtype.count()\n",
    "mask_couples_children = household_sizes[(household_types == 'Couple with dependent children') & (household_sizes <= 2)]\n",
    "mask_couples_no_children = household_sizes[(household_types == 'Couple without dependent children') & (household_sizes != 2)]\n",
    "invalids = (\n",
    "    household_sizes[(household_types == 'Couple with dependent children') & (household_sizes <= 2)] |\n",
    "    household_sizes[(household_types == 'Couple without dependent children') & (household_sizes != 2)] |\n",
    "    household_sizes[(household_types == 'Lone parent with dependent children') & (household_sizes < 2)] |\n",
    "    household_sizes[(household_types == 'Multi-person household') & (household_sizes <= 2)]\n",
    ")\n",
    "\n",
    "seed.drop(labels=invalids.index, level=0, inplace=True)\n",
    "\n",
    "\n",
    "print(\"{} households are invalid and were removed.\".format(invalids.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "household_types = seed.groupby(seed.index.get_level_values(0)).hhtype.first()\n",
    "household_sizes = seed.groupby(seed.index.get_level_values(0)).hhtype.count()\n",
    "assert (household_sizes[household_types == 'One person household'] == 1).all()\n",
    "assert (household_sizes[household_types == 'Couple with dependent children'] > 2).all()\n",
    "assert (household_sizes[household_types == 'Couple without dependent children'] == 2).all()\n",
    "assert (household_sizes[household_types == 'Lone parent with dependent children'] > 1).all()\n",
    "assert (household_sizes[household_types == 'Multi-person household'] > 2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert not ((seed.labour == 'above_74') & (seed.age <= 74)).any()\n",
    "assert not ((seed.labour == 'below_16') & (seed.age >= 16)).any()\n",
    "assert not ((seed.labour == 'below_16') & (seed.qualification != 'below_16')).any()\n",
    "assert not ((seed.labour != 'below_16') & (seed.qualification == 'below_16')).any()\n",
    "\n",
    "household_types = seed.groupby(seed.index.get_level_values(0)).hhtype.first()\n",
    "household_sizes = seed.groupby(seed.index.get_level_values(0)).hhtype.count()\n",
    "assert (household_sizes[household_types == 'One person household'] == 1).all()\n",
    "assert (household_sizes[household_types == 'Couple with dependent children'] > 2).all()\n",
    "assert (household_sizes[household_types == 'Lone parent with dependent children'] > 1).all()\n",
    "assert (household_sizes[household_types == 'Couple without dependent children'] == 2).all()\n",
    "assert (household_sizes[household_types == 'Multi-person household'] > 2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Synthetic Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using plain IPF\n",
    "\n",
    "This performs a fit of the individuals only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_in = seed.groupby(['labour', 'qualification']).count().reset_index().rename(columns={'age': 'total'})\n",
    "assert df_in.total.sum() == seed.age.count()\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xip = pd.Series(index=labour_data.columns)\n",
    "xpj = pd.Series(index=qualification_data.columns)\n",
    "\n",
    "for labour_status in labour_data.columns:\n",
    "    xip[labour_status] = labour_data[labour_status].sum()\n",
    "\n",
    "for qualification in qualification_data.columns:\n",
    "    xpj[qualification] = qualification_data[qualification].sum()\n",
    "\n",
    "aggregates = [xip, xpj]\n",
    "dimensions = [['labour'], ['qualification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipfn import *\n",
    "\n",
    "IPF = ipfn.ipfn(\n",
    "    df_in,\n",
    "    aggregates, \n",
    "    dimensions\n",
    ")\n",
    "df_out = IPF.iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert df_out.total.sum() - usual_residents.sum().sum() < 1\n",
    "assert all((df_out.groupby('qualification').total.sum() - qualification_data.sum()) < 1)\n",
    "assert all((df_out.groupby('labour').total.sum() - labour_data.sum()) < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#synthetic_population = create_synthetic_population(\n",
    "#    df=df_out,\n",
    "#    column_names=['qualification', 'labour'],\n",
    "#    pop_size=usual_residents.sum().sum(),\n",
    "#    seed='syntheticpopulation-haringey'\n",
    "#)\n",
    "#synthetic_population.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HIPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from ktp.synthpop import fit_hipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = fit_hipf(\n",
    "    reference_sample=seed,\n",
    "    controls_households={'hhtype': household_data.sum().to_dict()},\n",
    "    controls_individuals={\n",
    "        'labour': labour_data.sum().to_dict(),\n",
    "        'qualification': qualification_data.sum().to_dict()\n",
    "    },\n",
    "    residuals_tol=0.0001,\n",
    "    weights_tol=0.0001,\n",
    "    maxiter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert NUMBER_HOUSEHOLDS - weights.sum() < 0.1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dev]",
   "language": "python",
   "name": "conda-env-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
