{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import namedtuple\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of the toy example of the HIPF paper\n",
    "\n",
    "This notebook successfully replicates the Hierarchical Iterative Proportional Fitting (HIPF) algorithm on a toy example. Both the algorithm and the toy example are taken from the original paper on HIPF: \n",
    "\n",
    "> MÃ¼ller and Axhausen 2011: \"Hierarchical IPF: Generating a synthetic population for Switzerland\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixture and expected output\n",
    "\n",
    "In the following, the input data and expected output data is prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HouseholdType = namedtuple('HouseholdType', ['household_ids', 'a', 'alpha', 'expansion_factors'])\n",
    "household_types = []\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(1, 23), \n",
    "    a=True,\n",
    "    alpha=[True, False, False],\n",
    "    expansion_factors=[1.37, 1.36, 1.33, 1.28, 1.18]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(23, 44), \n",
    "    a=True,\n",
    "    alpha=[True, False],\n",
    "    expansion_factors=[1.37, 1.57, 1.61, 1.61, 1.50]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(44, 65), \n",
    "    a=True,\n",
    "    alpha=[False, False, False],\n",
    "    expansion_factors=[1.37, 0.94, 0.92, 0.75, 0.54]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(65, 81), \n",
    "    a=False,\n",
    "    alpha=[False, False],\n",
    "    expansion_factors=[0.64, 0.44, 0.45, 0.38, 0.28]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(81, 97), \n",
    "    a=False,\n",
    "    alpha=[True, False, False],\n",
    "    expansion_factors=[0.64, 0.64, 0.62, 0.66, 0.68]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(97, 109), \n",
    "    a=False,\n",
    "    alpha=[False],\n",
    "    expansion_factors=[0.64, 0.44, 0.48, 0.38, 0.26]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(109, 120), \n",
    "    a=True,\n",
    "    alpha=[False, False],\n",
    "    expansion_factors=[1.37, 0.94, 0.97, 0.75, 0.49]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(120, 129), \n",
    "    a=True,\n",
    "    alpha=[False],\n",
    "    expansion_factors=[1.37, 0.94, 1.01, 0.75, 0.45]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(129, 137), \n",
    "    a=False,\n",
    "    alpha=[True, True, False],\n",
    "    expansion_factors=[0.64, 0.83, 0.82, 1.00, 1.30]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(137, 145), \n",
    "    a=True,\n",
    "    alpha=[True, True, False],\n",
    "    expansion_factors=[1.37, 1.77, 1.73, 1.95, 2.24]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(145, 152), \n",
    "    a=False,\n",
    "    alpha=[True, False],\n",
    "    expansion_factors=[0.64, 0.74, 0.75, 0.82, 0.87]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(152, 159), \n",
    "    a=False,\n",
    "    alpha=[False, False, False],\n",
    "    expansion_factors=[0.64, 0.44, 0.43, 0.38, 0.31]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(159, 165), \n",
    "    a=True,\n",
    "    alpha=[True],\n",
    "    expansion_factors=[1.37, 2.19, 2.35, 2.76, 3.27]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(165, 171), \n",
    "    a=True,\n",
    "    alpha=[True, True],\n",
    "    expansion_factors=[1.37, 2.19, 2.25, 2.75, 3.58]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(171, 174), \n",
    "    a=False,\n",
    "    alpha=[True],\n",
    "    expansion_factors=[0.64, 1.03, 1.11, 1.41, 1.89]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(174, 176), \n",
    "    a=True,\n",
    "    alpha=[True, True, True],\n",
    "    expansion_factors=[1.37, 2.19, 2.14, 2.74, 3.92]\n",
    "))\n",
    "household_types.append(HouseholdType(\n",
    "    household_ids=range(176, 177), \n",
    "    a=False,\n",
    "    alpha=[True, True],\n",
    "    expansion_factors=[0.64, 1.03, 1.06, 1.40, 2.07]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_tuples = itertools.chain(*(itertools.product(ht.household_ids, range(1, len(ht.alpha) + 1)) \n",
    "                              for ht in household_types))\n",
    "index = pd.MultiIndex.from_tuples(list(id_tuples), names=['household_id', 'person_id'])\n",
    "ref_sample = pd.DataFrame(index=index, columns=['a', 'alpha'])\n",
    "for ht in household_types:\n",
    "    ref_sample.ix[ht.household_ids[0]: ht.household_ids[-1], 'a'] = ht.a\n",
    "    for p, alpha in enumerate(ht.alpha):\n",
    "        ref_sample.loc[(slice(ht.household_ids[0], ht.household_ids[-1]), p + 1), 'alpha'] = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert ref_sample.groupby(ref_sample.index.get_level_values(0)).a.count().count() == 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected_expansion_factors = pd.DataFrame(\n",
    "    index=ref_sample.groupby(ref_sample.index.get_level_values(0)).count().index.get_level_values(0), \n",
    "    columns=[0, 1, 4, 5, 10], \n",
    "    dtype=np.float64\n",
    ")\n",
    "expected_expansion_factors[0] = 1.\n",
    "for ht in household_types:\n",
    "    for household_id in ht.household_ids:\n",
    "        expected_expansion_factors.ix[household_id, 1] = ht.expansion_factors[0]\n",
    "        expected_expansion_factors.ix[household_id, 4] = ht.expansion_factors[1]\n",
    "        expected_expansion_factors.ix[household_id, 5] = ht.expansion_factors[2]\n",
    "        expected_expansion_factors.ix[household_id, 10] = ht.expansion_factors[3]\n",
    "        expected_expansion_factors.ix[household_id, 'infinity'] = ht.expansion_factors[4]\n",
    "expected_expansion_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.util.testing import assert_series_equal\n",
    "\n",
    "def assert_expansion_factors_equal(expected_expansion_factors, expansion_factors):\n",
    "    assert_series_equal(expected_expansion_factors, expansion_factors, check_less_precise=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running HIPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors = pd.DataFrame(\n",
    "    index=ref_sample.groupby(ref_sample.index.get_level_values(0)).count().index.get_level_values(0), \n",
    "    data=1.0, \n",
    "    columns=[0], \n",
    "    dtype=np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_expansion_factors_equal(expected_expansion_factors[0], expansion_factors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_households(expansion_factors, total_car):\n",
    "    new_expansion_factors = expansion_factors.copy()\n",
    "    for household_id in expansion_factors.index:\n",
    "        ah = ref_sample.loc[(household_id, 1), 'a']\n",
    "        mask = ref_sample.groupby(ref_sample.index.get_level_values(0)).a.first() == ah\n",
    "        new_expansion_factors[household_id] = expansion_factors.loc[household_id] * total_car[ah] / expansion_factors[mask].sum()\n",
    "    return new_expansion_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_car = pd.Series(index=[True, False], data=[145, 45])\n",
    "expansion_factors[1] = fit_households(expansion_factors[0], total_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_expansion_factors_equal(expected_expansion_factors[1], expansion_factors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expand_expansion_factors_to_person(expansion_factors):\n",
    "    person_expansion_factors = expansion_factors.copy()\n",
    "    person_expansion_factors = pd.DataFrame(person_expansion_factors)\n",
    "    person_expansion_factors['person_id'] = 1\n",
    "    person_expansion_factors.set_index('person_id', append=True, inplace=True)\n",
    "    person_expansion_factors = person_expansion_factors.reindex(ref_sample.index)\n",
    "    person_expansion_factors.fillna(method='ffill', inplace=True)\n",
    "    return person_expansion_factors[expansion_factors.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expansion_factors_p = expand_expansion_factors_to_person(expansion_factors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert math.isclose(expansion_factors_p.sum() - 8.27, 434, abs_tol=0.01)\n",
    "assert math.isclose(expansion_factors_p[ref_sample.alpha == True].sum() + 85.18, 227, abs_tol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_person(expansion_factors, total_employment):\n",
    "    new_expansion_factors = expansion_factors.copy()\n",
    "    for person_id in expansion_factors.index:\n",
    "        alphah = ref_sample.loc[person_id, 'alpha']\n",
    "        mask = ref_sample.alpha == alphah\n",
    "        new_expansion_factors.loc[person_id] = expansion_factors.loc[person_id] * total_employment[alphah] / expansion_factors[mask].sum()\n",
    "    return new_expansion_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_employment = {True: 227, False: 207}\n",
    "new_expansion_factors_p = fit_person(expansion_factors_p, total_employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert math.isclose(new_expansion_factors_p.sum(), 434, abs_tol=0.01)\n",
    "assert math.isclose(new_expansion_factors_p[ref_sample.alpha == True].sum(), 227, abs_tol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggregate_person_expansion_factors_to_household(person_expansion_factors):\n",
    "    return person_expansion_factors.groupby(person_expansion_factors.index.get_level_values(0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors[4] = aggregate_person_expansion_factors_to_household(new_expansion_factors_p)\n",
    "assert_expansion_factors_equal(expected_expansion_factors[4], expansion_factors[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "\n",
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "\n",
    "def rescale_expansion_factors(expansion_factors):\n",
    "    largest_household_size = ref_sample.groupby(ref_sample.index.get_level_values(0)).alpha.count().max()\n",
    "    Fp = [expansion_factors[ref_sample.groupby(ref_sample.index.get_level_values(0)).alpha.count() == p].sum()\n",
    "          for p in range(0, largest_household_size + 1)]\n",
    "    polynom = [(190 / 434 * p - 1) * Fp[p] for p in range(0, largest_household_size + 1)]\n",
    "    roots = Polynomial(polynom).roots()\n",
    "    dx = list(filter(lambda x: np.real(x) > 0, filterfalse(lambda x: np.iscomplex(x), roots)))\n",
    "    assert len(dx) == 1\n",
    "    d = np.real(dx[0])\n",
    "    c = 190 / sum([Fp[p] * d ** p for p in range(1, largest_household_size + 1)])\n",
    "    fhprime_by_fh = {p: c * d ** p for p in range(1, largest_household_size + 1)}\n",
    "    \n",
    "    new_expansion_factors = expansion_factors.copy()\n",
    "    for household_id in expansion_factors.index:\n",
    "        household_size = ref_sample.groupby(ref_sample.index.get_level_values(0)).alpha.count()[household_id]\n",
    "        new_expansion_factors[household_id] = fhprime_by_fh[household_size] * expansion_factors[household_id]\n",
    "    return new_expansion_factors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors[5] = rescale_expansion_factors(expansion_factors[4])\n",
    "assert_expansion_factors_equal(expected_expansion_factors[5], expansion_factors[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 6-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors[6] = fit_households(expansion_factors[5], total_car)\n",
    "expansion_factors_p = expand_expansion_factors_to_person(expansion_factors[6])\n",
    "new_expansion_factors_p = fit_person(expansion_factors_p, total_employment)\n",
    "expansion_factors[9] = aggregate_person_expansion_factors_to_household(new_expansion_factors_p)\n",
    "expansion_factors[10] = rescale_expansion_factors(expansion_factors[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_expansion_factors_equal(expected_expansion_factors[10], expected_expansion_factors[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate till convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_till_convergence(expansion_factors, abs_tol, rel_tol, maxiter):\n",
    "    for i in range(maxiter):\n",
    "        new_expansion_factors = fit_households(expansion_factors, total_car)\n",
    "        expansion_factors_p = expand_expansion_factors_to_person(new_expansion_factors)\n",
    "        expansion_factors_p = fit_person(expansion_factors_p, total_employment)\n",
    "        new_expansion_factors = aggregate_person_expansion_factors_to_household(expansion_factors_p)\n",
    "        new_expansion_factors = rescale_expansion_factors(new_expansion_factors)\n",
    "        if absolute_tolerance_reached(new_expansion_factors, total_car, total_employment, abs_tol):\n",
    "            print('Target tolerance reached in iteration {}.'.format(i))\n",
    "            break\n",
    "        if relative_tolerance_reached(new_expansion_factors, expansion_factors, rel_tol):\n",
    "            print(\"Expansion factors haven't changed anymore in iteration {}.\".format(i))\n",
    "            break\n",
    "        expansion_factors = new_expansion_factors\n",
    "    return expansion_factors\n",
    "\n",
    "\n",
    "def absolute_tolerance_reached(expansion_factors, total_car, total_employment, tol):\n",
    "    grand_total_h = expansion_factors.sum() / (total_car[True] + total_car[False]) - 1\n",
    "    total_cars = expansion_factors[ref_sample.groupby(ref_sample.index.get_level_values(0)).a.first() == True].sum() / total_car[True] - 1\n",
    "    expansion_factors_p = expand_expansion_factors_to_person(expansion_factors)\n",
    "    grand_total_p = expansion_factors_p.sum() / (total_employment[True] + total_employment[False]) - 1\n",
    "    total_employments = expansion_factors_p[ref_sample.alpha == True].sum() / total_employment[True] - 1\n",
    "    residuals = [grand_total_h, grand_total_p, total_cars, total_employments]\n",
    "    return pd.Series(residuals).abs().max() < tol\n",
    "\n",
    "\n",
    "def relative_tolerance_reached(new_expansion_factors, expansion_factors, rel_tol):\n",
    "    residuals = new_expansion_factors / expansion_factors - 1\n",
    "    return residuals.abs().max() < rel_tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expansion_factors['infinity'] = iterate_till_convergence(\n",
    "    expansion_factors=expansion_factors[10],\n",
    "    abs_tol=0.00001,\n",
    "    rel_tol=0.000000000001,\n",
    "    maxiter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert_expansion_factors_equal(expansion_factors['infinity'], expected_expansion_factors['infinity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Quod Erat Demonstrandum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dev]",
   "language": "python",
   "name": "conda-env-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
