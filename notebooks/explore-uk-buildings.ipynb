{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UKBUILDINGS_POINTS_FOLDER_PATH = Path('./data/ukbuildings/POINTS/')\n",
    "UKBUILDINGS_POLYGONS_FOLDER_PATH = Path('./data/ukbuildings/POLYGONS/')\n",
    "LONDON_BOUNDARY_FILE_URL = 'https://files.datapress.com/london/dataset/statistical-gis-boundary-files-london/2016-10-03T13:52:28/statistical-gis-boundaries-london.zip'\n",
    "LONDON_HOUSING_SURVEY_URL = 'https://files.datapress.com/london/dataset/2011-census-housing/visualisation-data-housing.zip'\n",
    "\n",
    "BOROUGH_SHAPE_FILE_PATH = Path('./statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp')\n",
    "WARD_SHAPE_FILE_PATH = Path('./statistical-gis-boundaries-london/ESRI/London_Ward.shp')\n",
    "HOUSING_FILE_PATH = Path('./HOUSING.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests_cache.install_cache('../build/cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HB_MIN_X = 500000\n",
    "HB_MAX_X = 600000\n",
    "HB_MIN_Y = 100000\n",
    "HB_MAX_Y = 200000\n",
    "\n",
    "\n",
    "def production_blocks(minx, miny, maxx, maxy):\n",
    "    \"\"\"Generator of GeoInformationGroup production blocks.\n",
    "    \n",
    "    Based on a rectangular bounding box defined in OS national grid, \n",
    "    this generator will yield all GeoInformationGroup production blocks \n",
    "    that are touched by the box.\n",
    "    \n",
    "    Supports only bounding boxes entirely in the HB production block\n",
    "    reference.\n",
    "    \n",
    "    Parameters:\n",
    "        * minx, miny, maxx, maxy: the parameters of the bounding box \n",
    "                                  defined in OS national grid\n",
    "    \n",
    "    Yields:\n",
    "        The string name of each bounding box.\n",
    "    \"\"\"\n",
    "    assert minx >= HB_MIN_X # supports only HB\n",
    "    assert miny >= HB_MIN_Y # supports only HB\n",
    "    assert maxx <= HB_MAX_X # supports only HB\n",
    "    assert maxy <= HB_MAX_Y # supports only HB\n",
    "    start_x = (int(minx) - HB_MIN_X) // 5000 + 1\n",
    "    end_x = (int(maxx) - HB_MIN_X) // 5000 + 1\n",
    "    start_y = (int(miny) - HB_MIN_Y) // 5000 + 1\n",
    "    end_y = (int(maxy) - HB_MIN_Y) // 5000 + 1\n",
    "    for x in range(start_x, end_x + 1):\n",
    "        for y in range(start_y, end_y + 1):\n",
    "            yield 'HB{:0>2}{:0>2}'.format(x, y)\n",
    "\n",
    "assert set(production_blocks(500000, 100000, 500001, 100001)) == set(['HB0101'])\n",
    "assert set(production_blocks(500000, 100000, 500000.1, 100000.1)) == set(['HB0101'])\n",
    "assert set(production_blocks(505000, 100000, 505001, 100001)) == set(['HB0201'])\n",
    "assert set(production_blocks(500000, 105000, 500001, 105001)) == set(['HB0102'])\n",
    "assert set(production_blocks(500000, 100000, 505000, 100001)) == set(['HB0101', 'HB0201'])\n",
    "assert set(production_blocks(500000, 100000, 500001, 105000)) == set(['HB0101', 'HB0102'])\n",
    "assert set(production_blocks(504999, 100000, 505001, 100001)) == set(['HB0101', 'HB0201'])\n",
    "assert set(production_blocks(504999.9, 100000, 505001, 100001)) == set(['HB0101', 'HB0201'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ukbuildings_polygon_file(production_blocks):\n",
    "    \"\"\"Generator of file paths of UKBuilding production blocks.\n",
    "    \n",
    "    Parameters:\n",
    "        * an iterable of production block names\n",
    "        \n",
    "    Yields:\n",
    "        * file path of the file containing the production block\n",
    "    \"\"\"\n",
    "    for production_block in production_blocks:\n",
    "        yield list(UKBUILDINGS_POLYGONS_FOLDER_PATH.glob('{}*.shp'.format(production_block)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Haringey Buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Haringey shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_BOUNDARY_FILE_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-boundary-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    borough_file = Path(tmpdir) / BOROUGH_SHAPE_FILE_PATH\n",
    "    borough_data = gpd.read_file(borough_file.as_posix())\n",
    "borough_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "haringey = borough_data[borough_data.NAME == 'Haringey'].geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "haringey.boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all UKBuilding files that include Haringey buildings\n",
    "\n",
    "Theoretically we could read all UKBuilding files, but the reading and especially the merging takes too long. So in a smarter way, let's filter all files not including Haringey buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = None\n",
    "for shape_file_path in ukbuildings_polygon_file(production_blocks(*haringey.bounds)):\n",
    "    print('Reading {}'.format(shape_file_path))\n",
    "    shape_file_data = gpd.read_file(shape_file_path.as_posix())\n",
    "    if ukb_data is None:\n",
    "        ukb_data = shape_file_data\n",
    "    else:\n",
    "        ukb_data = ukb_data.append(shape_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'BASE': np.bool8,\n",
    "    'BEC': np.int8,\n",
    "    'BUNG': np.bool8,\n",
    "    'DOR': np.int16,\n",
    "    'DPS': np.int16,\n",
    "    'GET': 'category',\n",
    "    'MBN': 'category',\n",
    "    'NAB': 'category',\n",
    "    'RBCA': 'category',\n",
    "    'RBCAT': 'category',\n",
    "    'RBCC': 'category',\n",
    "    'RBCS': np.bool8,\n",
    "    'RBCT': 'category',\n",
    "    'RBCTT': 'category',\n",
    "    'RBN': np.int8,\n",
    "    # TODO RBQ ??\n",
    "    # TODO KBD ??\n",
    "    'RDT': 'category',\n",
    "    'RDTT': 'category',\n",
    "    'RNR': 'category',\n",
    "    'RRN': np.int8,\n",
    "    'RRT': 'category',\n",
    "    'RRTT': 'category',\n",
    "    'RWN': np.int8,\n",
    "    'RWT': 'category',\n",
    "    'RWTT': 'category',\n",
    "    'SBC': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = ukb_data.astype(col_types)\n",
    "ukb_data = gpd.GeoDataFrame(ukb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut out Haringey\n",
    "\n",
    "The read in files contain all buildings from all GeoInformationGroup production block files in which Haringey buildings are present. Let's filter for only Haringey buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.prepared import prep\n",
    "haringey_prep = prep(haringey) # improves performace for the next step\n",
    "in_haringey_mask = ukb_data.geometry.map(haringey_prep.contains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = ukb_data[ukb_data.geometry.map(haringey_prep.contains)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_poly = shapely.geometry.MultiPolygon([polygon for polygon in ukb_data.geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert ukb_poly.convex_hull.difference(haringey.convex_hull).area / 1000000 < 2\n",
    "assert haringey.convex_hull.difference(ukb_poly.convex_hull).area / 1000000 < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the convex hull of all Haringey buildings in the UKBuildings dataset and the convex hull of the borough boundary is smaller than 2 * 2km<sup>2</sup>. _(Arbitrarily chosen to be small enough.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to Tottenham\n",
    "\n",
    "As for the moment, let's look at Tottenham only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_BOUNDARY_FILE_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-boundary-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    ward_file = Path(tmpdir) / WARD_SHAPE_FILE_PATH\n",
    "    ward_data = gpd.read_file(ward_file.as_posix())\n",
    "ward_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham = ward_data[(ward_data.BOROUGH == 'Haringey') & ward_data.NAME.map(lambda name: 'Tottenham' in name)]\n",
    "tottenham = tottenham.dissolve(by=lambda x: 1).iloc[0].geometry\n",
    "tottenham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_prep = prep(tottenham) # improves performace for the next step\n",
    "in_tottenham_mask = ukb_data.geometry.map(tottenham_prep.contains)\n",
    "ukb_data = ukb_data[in_tottenham_mask]\n",
    "ukb_data.dissolve(by='UBN').plot(linewidth=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Number of Housholds\n",
    "\n",
    "Retrieve the number of households in the area, based on the [2011 survey data](https://data.london.gov.uk/dataset/2011-census-housing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_HOUSING_SURVEY_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-housing-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    housing_file = Path(tmpdir) / HOUSING_FILE_PATH\n",
    "    housing_data = pd.read_excel(\n",
    "        housing_file, \n",
    "        sheetname='2011 Data',\n",
    "        skiprows=[0],\n",
    "        header=[0]\n",
    "    )\n",
    "housing_data.rename(columns={'Unnamed: 1': 'area_type'}, inplace=True)\n",
    "housing_data['area_type'] = housing_data['area_type'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_housing_data = housing_data[(housing_data.DISTLABEL == 'Haringey') & \n",
    "                                      (housing_data.area_type == 'ward') & \n",
    "                                       housing_data.ZONELABEL.map(lambda label: 'Tottenham' in label)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_housing_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars_total = (\n",
    "    tottenham_housing_data['No cars or vans in household'] +\n",
    "    tottenham_housing_data['1 car or van in household'] +\n",
    "    tottenham_housing_data['2 cars or vans in household'] +\n",
    "    tottenham_housing_data['3 cars or vans in household'] +\n",
    "    tottenham_housing_data['4 or more cars or vans in household']\n",
    ")\n",
    "ownership_total = (\n",
    "    tottenham_housing_data['Owned: Total'] +\n",
    "    tottenham_housing_data['Shared ownership (part owned and part rented)'] +\n",
    "    tottenham_housing_data['Social rented: Total'] +\n",
    "    tottenham_housing_data['Private rented: Total'] +\n",
    "    tottenham_housing_data['Living rent free']\n",
    ")\n",
    "share_total = (\n",
    "    tottenham_housing_data['Unshared dwelling: Total'] +\n",
    "    tottenham_housing_data['Shared dwelling']\n",
    ")\n",
    "heating_total = (\n",
    "    tottenham_housing_data['No central heating'] +\n",
    "    tottenham_housing_data['Gas central heating'] +\n",
    "    tottenham_housing_data['Electric (including storage heaters) central heating'] +\n",
    "    tottenham_housing_data['Oil central heating'] +\n",
    "    tottenham_housing_data['Solid fuel (for example wood, coal) central heating'] +\n",
    "    tottenham_housing_data['Other central heating'] + \n",
    "    tottenham_housing_data['Two or more types of central heating']\n",
    "    \n",
    ")\n",
    "assert cars_total == heating_total\n",
    "assert cars_total == share_total\n",
    "assert cars_total == ownership_total\n",
    "cars_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11309 households in Tottenham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## From UKBuildings to Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data.UBN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
