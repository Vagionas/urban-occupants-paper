{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import io\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import requests\n",
    "import requests_cache\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UKBUILDINGS_POINTS_FOLDER_PATH = Path('./data/ukbuildings/POINTS/')\n",
    "UKBUILDINGS_POLYGONS_FOLDER_PATH = Path('./data/ukbuildings/POLYGONS/')\n",
    "LONDON_BOUNDARY_FILE_URL = 'https://files.datapress.com/london/dataset/statistical-gis-boundary-files-london/2016-10-03T13:52:28/statistical-gis-boundaries-london.zip'\n",
    "LONDON_HOUSING_SURVEY_URL = 'https://files.datapress.com/london/dataset/2011-census-housing/visualisation-data-housing.zip'\n",
    "\n",
    "BOROUGH_SHAPE_FILE_PATH = Path('./statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp')\n",
    "WARD_SHAPE_FILE_PATH = Path('./statistical-gis-boundaries-london/ESRI/London_Ward.shp')\n",
    "HOUSING_FILE_PATH = Path('./HOUSING.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests_cache.install_cache('../build/cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HB_MIN_X = 500000\n",
    "HB_MAX_X = 600000\n",
    "HB_MIN_Y = 100000\n",
    "HB_MAX_Y = 200000\n",
    "\n",
    "\n",
    "def production_blocks(minx, miny, maxx, maxy):\n",
    "    \"\"\"Generator of GeoInformationGroup production blocks.\n",
    "    \n",
    "    Based on a rectangular bounding box defined in OS national grid, \n",
    "    this generator will yield all GeoInformationGroup production blocks \n",
    "    that are touched by the box.\n",
    "    \n",
    "    Supports only bounding boxes entirely in the HB production block\n",
    "    reference.\n",
    "    \n",
    "    Parameters:\n",
    "        * minx, miny, maxx, maxy: the parameters of the bounding box \n",
    "                                  defined in OS national grid\n",
    "    \n",
    "    Yields:\n",
    "        The string name of each bounding box.\n",
    "    \"\"\"\n",
    "    assert minx >= HB_MIN_X # supports only HB\n",
    "    assert miny >= HB_MIN_Y # supports only HB\n",
    "    assert maxx <= HB_MAX_X # supports only HB\n",
    "    assert maxy <= HB_MAX_Y # supports only HB\n",
    "    start_x = (int(minx) - HB_MIN_X) // 5000 + 1\n",
    "    end_x = (int(maxx) - HB_MIN_X) // 5000 + 1\n",
    "    start_y = (int(miny) - HB_MIN_Y) // 5000 + 1\n",
    "    end_y = (int(maxy) - HB_MIN_Y) // 5000 + 1\n",
    "    for x in range(start_x, end_x + 1):\n",
    "        for y in range(start_y, end_y + 1):\n",
    "            yield 'HB{:0>2}{:0>2}'.format(x, y)\n",
    "\n",
    "assert set(production_blocks(500000, 100000, 500001, 100001)) == set(['HB0101'])\n",
    "assert set(production_blocks(500000, 100000, 500000.1, 100000.1)) == set(['HB0101'])\n",
    "assert set(production_blocks(505000, 100000, 505001, 100001)) == set(['HB0201'])\n",
    "assert set(production_blocks(500000, 105000, 500001, 105001)) == set(['HB0102'])\n",
    "assert set(production_blocks(500000, 100000, 505000, 100001)) == set(['HB0101', 'HB0201'])\n",
    "assert set(production_blocks(500000, 100000, 500001, 105000)) == set(['HB0101', 'HB0102'])\n",
    "assert set(production_blocks(504999, 100000, 505001, 100001)) == set(['HB0101', 'HB0201'])\n",
    "assert set(production_blocks(504999.9, 100000, 505001, 100001)) == set(['HB0101', 'HB0201'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ukbuildings_polygon_file(production_blocks):\n",
    "    \"\"\"Generator of file paths of UKBuilding production blocks.\n",
    "    \n",
    "    Parameters:\n",
    "        * an iterable of production block names\n",
    "        \n",
    "    Yields:\n",
    "        * file path of the file containing the production block\n",
    "    \"\"\"\n",
    "    for production_block in production_blocks:\n",
    "        yield list(UKBUILDINGS_POLYGONS_FOLDER_PATH.glob('{}*.shp'.format(production_block)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_SOMEWHERE_IN_HARINGEY = [51.585978320592275, -0.00]\n",
    "\n",
    "\n",
    "def aerial_base_map(location):\n",
    "    \"\"\"Creates an interactive aerial map at the given location.\n",
    "    \n",
    "    If there is no mapbox access token, an OpenStreetMap will be returned. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        mapbox_access_token = os.environ['MAPBOX_ACCESS_TOKEN']\n",
    "    except KeyError:\n",
    "        mapbox_access_token = None\n",
    "    if mapbox_access_token is not None:\n",
    "        base_map = folium.Map(\n",
    "            location=location, \n",
    "            zoom_start=18, \n",
    "            tiles='https://api.mapbox.com/styles/v1/mapbox/satellite-streets-v10/tiles/256/{{z}}/{{x}}/{{y}}?access_token={}'.format(mapbox_access_token),\n",
    "            attr=\"© Mapbox, © OpenStreetMap\",\n",
    "            API_key='not necessary' # folium expects it here, but Mapbox expects it in the tiles url\n",
    "        )\n",
    "    else:\n",
    "        base_map = default_base_map(location)\n",
    "    return base_map\n",
    "\n",
    "\n",
    "def default_base_map(location):\n",
    "    \"\"\"Creates an interactive OpenStreetMap at the given location.\"\"\"\n",
    "    return folium.Map(\n",
    "            location=location,\n",
    "            zoom_start=18,\n",
    "            tiles='OpenStreetMap'\n",
    "        )\n",
    "            \n",
    "def map_buildings(buildings, aerial=False):\n",
    "    buildings = buildings.to_crs({'init': 'epsg:4258'})\n",
    "    if aerial:\n",
    "        base_map = aerial_base_map(_SOMEWHERE_IN_HARINGEY)\n",
    "    else:\n",
    "        base_map = default_base_map(_SOMEWHERE_IN_HARINGEY)\n",
    "    bounds = [list(buildings.dissolve(by=lambda x: 1).geometry.iloc[0].envelope.boundary.coords)[i] for i in [0, 2]]\n",
    "    bounds = [(lat, long) for long, lat in bounds]\n",
    "    base_map.fit_bounds(bounds)\n",
    "    with tempfile.TemporaryDirectory(prefix='geojson-') as geojson_dir:\n",
    "        file_name = os.path.join(geojson_dir, 'temp.json')\n",
    "        buildings.geometry.to_file(file_name, driver='GeoJSON')\n",
    "        with open(file_name, 'r') as geojson:\n",
    "            folium.GeoJson(geojson, name='geojson').add_to(base_map)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dissolve(df, by):\n",
    "    \"\"\"Dissolve retaining CRS.\n",
    "    \n",
    "    See https://github.com/geopandas/geopandas/pull/389.\n",
    "    \"\"\"\n",
    "    crs = df.crs\n",
    "    new_df = df.dissolve(by=by)\n",
    "    new_df.crs = crs\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Haringey Buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Haringey shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_BOUNDARY_FILE_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-boundary-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    borough_file = Path(tmpdir) / BOROUGH_SHAPE_FILE_PATH\n",
    "    borough_data = gpd.read_file(borough_file.as_posix())\n",
    "borough_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "haringey = borough_data[borough_data.NAME == 'Haringey'].geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "haringey.boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all UKBuilding files that include Haringey buildings\n",
    "\n",
    "Theoretically we could read all UKBuilding files, but the reading and especially the merging takes too long. So in a smarter way, let's filter all files not including Haringey buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = None\n",
    "for shape_file_path in ukbuildings_polygon_file(production_blocks(*haringey.bounds)):\n",
    "    print('Reading {}'.format(shape_file_path))\n",
    "    shape_file_data = gpd.read_file(shape_file_path.as_posix())\n",
    "    if ukb_data is None:\n",
    "        ukb_data = shape_file_data\n",
    "    else:\n",
    "        ukb_data = ukb_data.append(shape_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crs = ukb_data.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'BASE': np.bool8,\n",
    "    'BEC': np.int8,\n",
    "    'BUNG': np.bool8,\n",
    "    'DOR': np.int16,\n",
    "    'DPS': np.int16,\n",
    "    'GET': 'category',\n",
    "    'MBN': 'category',\n",
    "    'NAB': 'category',\n",
    "    'RBCA': 'category',\n",
    "    'RBCAT': 'category',\n",
    "    'RBCC': 'category',\n",
    "    'RBCS': np.bool8,\n",
    "    'RBCT': 'category',\n",
    "    'RBCTT': 'category',\n",
    "    'RBN': np.int8,\n",
    "    # TODO RBQ ??\n",
    "    # TODO KBD ??\n",
    "    'RDT': 'category',\n",
    "    'RDTT': 'category',\n",
    "    'RNR': 'category',\n",
    "    'RRN': np.int8,\n",
    "    'RRT': 'category',\n",
    "    'RRTT': 'category',\n",
    "    'RWN': np.int8,\n",
    "    'RWT': 'category',\n",
    "    'RWTT': 'category',\n",
    "    'SBC': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = ukb_data.astype(col_types)\n",
    "ukb_data = gpd.GeoDataFrame(ukb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data.crs = crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut out Haringey\n",
    "\n",
    "The read in files contain all buildings from all GeoInformationGroup production block files in which Haringey buildings are present. Let's filter for only Haringey buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.prepared import prep\n",
    "haringey_prep = prep(haringey) # improves performace for the next step\n",
    "in_haringey_mask = ukb_data.geometry.map(haringey_prep.contains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_data = ukb_data[in_haringey_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ukb_poly = shapely.geometry.MultiPolygon([polygon for polygon in ukb_data.geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert ukb_poly.convex_hull.difference(haringey.convex_hull).area / 1000000 < 2\n",
    "assert haringey.convex_hull.difference(ukb_poly.convex_hull).area / 1000000 < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the convex hull of all Haringey buildings in the UKBuildings dataset and the convex hull of the borough boundary is smaller than 2 * 2km<sup>2</sup>. _(Arbitrarily chosen to be small enough.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to Tottenham\n",
    "\n",
    "As for the moment, let's look at Tottenham only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_BOUNDARY_FILE_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-boundary-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    ward_file = Path(tmpdir) / WARD_SHAPE_FILE_PATH\n",
    "    ward_data = gpd.read_file(ward_file.as_posix())\n",
    "ward_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham = ward_data[(ward_data.BOROUGH == 'Haringey') & ward_data.NAME.map(lambda name: 'Tottenham' in name)]\n",
    "tottenham = tottenham.dissolve(by=lambda x: 1).iloc[0].geometry\n",
    "tottenham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(ukb_data.dissolve(by='UBN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_prep = prep(tottenham) # improves performace for the next step\n",
    "in_tottenham_mask = ukb_data.geometry.map(tottenham_prep.contains)\n",
    "ukb_data = ukb_data[in_tottenham_mask]\n",
    "\n",
    "map_buildings(dissolve(ukb_data, by='UBN'), aerial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Number of Housholds\n",
    "\n",
    "Retrieve the number of households in the area, based on the [2011 survey data](https://data.london.gov.uk/dataset/2011-census-housing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(LONDON_HOUSING_SURVEY_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "with tempfile.TemporaryDirectory(prefix='london-housing-files') as tmpdir:\n",
    "    z.extractall(path=tmpdir)\n",
    "    housing_file = Path(tmpdir) / HOUSING_FILE_PATH\n",
    "    housing_data = pd.read_excel(\n",
    "        housing_file, \n",
    "        sheetname='2011 Data',\n",
    "        skiprows=[0],\n",
    "        header=[0]\n",
    "    )\n",
    "housing_data.rename(columns={'Unnamed: 1': 'area_type'}, inplace=True)\n",
    "housing_data['area_type'] = housing_data['area_type'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_housing_data = housing_data[(housing_data.DISTLABEL == 'Haringey') & \n",
    "                                      (housing_data.area_type == 'ward') & \n",
    "                                       housing_data.ZONELABEL.map(lambda label: 'Tottenham' in label)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottenham_housing_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars_total = (\n",
    "    tottenham_housing_data['No cars or vans in household'] +\n",
    "    tottenham_housing_data['1 car or van in household'] +\n",
    "    tottenham_housing_data['2 cars or vans in household'] +\n",
    "    tottenham_housing_data['3 cars or vans in household'] +\n",
    "    tottenham_housing_data['4 or more cars or vans in household']\n",
    ")\n",
    "ownership_total = (\n",
    "    tottenham_housing_data['Owned: Total'] +\n",
    "    tottenham_housing_data['Shared ownership (part owned and part rented)'] +\n",
    "    tottenham_housing_data['Social rented: Total'] +\n",
    "    tottenham_housing_data['Private rented: Total'] +\n",
    "    tottenham_housing_data['Living rent free']\n",
    ")\n",
    "share_total = (\n",
    "    tottenham_housing_data['Unshared dwelling: Total'] +\n",
    "    tottenham_housing_data['Shared dwelling']\n",
    ")\n",
    "heating_total = (\n",
    "    tottenham_housing_data['No central heating'] +\n",
    "    tottenham_housing_data['Gas central heating'] +\n",
    "    tottenham_housing_data['Electric (including storage heaters) central heating'] +\n",
    "    tottenham_housing_data['Oil central heating'] +\n",
    "    tottenham_housing_data['Solid fuel (for example wood, coal) central heating'] +\n",
    "    tottenham_housing_data['Other central heating'] + \n",
    "    tottenham_housing_data['Two or more types of central heating']\n",
    "    \n",
    ")\n",
    "assert cars_total == heating_total\n",
    "assert cars_total == share_total\n",
    "assert cars_total == ownership_total\n",
    "cars_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11309 households in Tottenham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## From UKBuildings to Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ukb_data.UBN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
